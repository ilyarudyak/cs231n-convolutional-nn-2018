{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "import time, os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.rnn_layers import *\n",
    "from cs231n.captioning_solver import CaptioningSolver\n",
    "from cs231n.classifiers.rnn import CaptioningRNN\n",
    "from cs231n.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions\n",
    "from cs231n.image_utils import image_from_url\n",
    "from cs231n.layers import *\n",
    "from cs231n.rnn_layers import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the softmax forward and back propagation in more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "# build data and model\n",
    "small_data = load_coco_data(max_train=50)\n",
    "small_rnn_model = CaptioningRNN(\n",
    "          cell_type='rnn',\n",
    "          word_to_idx=small_data['word_to_idx'],\n",
    "          input_dim=small_data['train_features'].shape[1],\n",
    "          hidden_dim=512,\n",
    "          wordvec_dim=256,\n",
    "        )\n",
    "\n",
    "# get minibatch of data\n",
    "minibatch = sample_coco_minibatch(small_data,\n",
    "                                  batch_size=25,\n",
    "                                  split='train')\n",
    "\n",
    "# build captions and mask\n",
    "captions, features, urls = minibatch\n",
    "captions_in = captions[:, :-1]\n",
    "captions_out = captions[:, 1:]\n",
    "mask = (captions_out != small_rnn_model._null)\n",
    "\n",
    "# unpack weights\n",
    "W_proj, b_proj = small_rnn_model.params['W_proj'], small_rnn_model.params['b_proj']\n",
    "W_embed = small_rnn_model.params['W_embed']\n",
    "Wx, Wh, b = small_rnn_model.params['Wx'], small_rnn_model.params['Wh'], small_rnn_model.params['b']\n",
    "W_vocab, b_vocab = small_rnn_model.params['W_vocab'], small_rnn_model.params['b_vocab']\n",
    "loss, grads = 0.0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass up to softmax loss\n",
    "affine_out, affine_cache = affine_forward(features, W_proj, b_proj)\n",
    "captions_in_embed, embed_cache = word_embedding_forward(captions_in, W_embed)\n",
    "hidden_rnn, rnn_cache = rnn_forward(captions_in_embed, affine_out, Wx, Wh, b)\n",
    "scores, scores_cache = temporal_affine_forward(hidden_rnn, W_vocab, b_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 16, 1004)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best description of `softmax` loss that I know is in `cs224n` assignments. Suppose $\\hat{y} = softmax(x)$, then if $y$ is one-hot encoded we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$CE(y, \\hat{y}) = -\\sum_i{y_i log(\\hat{y}_i)} = -log(\\hat{y}_s) = -log(\\frac{e^{x_s}}{\\sum_j{e^{x_j}}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case correct classes are in `captions_out`. We need to extract those values from `scores`:\n",
    "\n",
    "> A temporal version of softmax loss for use in `RNNs`. We assume that we are\n",
    "    making predictions over a vocabulary of size `V` for each timestep of a\n",
    "    timeseries of length T, over a minibatch of size `N`. The input `x` gives scores\n",
    "    for all vocabulary elements at all timesteps, and `y` gives the indices of the\n",
    "    ground-truth element at each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 16, 1004), (25, 16))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape, captions_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,  12, 292,   9,  40, 236, 628,   8,  44,   3,   9, 318,   2,\n",
       "         0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_out[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we also need somehow combine losses over timesteps and minibatches:\n",
    "\n",
    "> We use a cross-entropy loss at each\n",
    "    timestep, summing the loss over all timesteps and averaging across the\n",
    "    minibatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have to use mask:\n",
    "\n",
    ">   As an additional complication, we may want to ignore the model output at some\n",
    "timesteps, since sequences of different length may have been combined into a\n",
    "minibatch and padded with NULL tokens. The optional mask argument tells us\n",
    "which elements should contribute to the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### back prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about backprop? We have to use the following result from `cs224n` (where `y` is one-hot encoded):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial CE(y, \\hat{y})}{\\partial \\theta} = \\hat{y} - y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we just need to subtract `1` from `probs` at the correct classes that are given by `captions_out`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 16, 1004)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to divide by `batch_size` - we average over batches as stated above. In case of masked values $CE(\\hat{y}, y)$ is just `0` and the gradient is `0` so we just need to multiply by the `mask`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we compute our loss? We have to:\n",
    "\n",
    "- compute softmax - we know that our scores are **before softmax** (see above);\n",
    "- then we have to extract scores for correct classes; and \n",
    "- compute losses for them (do not compute for padding); then take an average of those losses;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is easy. We are not going to compute it manually. Instead we use `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = softmax(scores, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 16, 1004)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(probs, axis=2)[0, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's also not too difficult. Let's first do it with a loop and then with indexing. Correct classes are in `captions_out`. We need to extract those classes from `probs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,  12, 292,   9,  40, 236, 628,   8,  44,   3,   9, 318,   2,\n",
       "         0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0010832205554948437, 0.0007169921412785972, 0.0006498031358371554)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0, 0, 4], probs[0, 1, 12], probs[0, 2, 292] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00108322, 0.00071699, 0.0006498 , 0.00082907, 0.00227525,\n",
       "       0.00113538, 0.00093542, 0.00100416, 0.00150696, 0.00094095,\n",
       "       0.00144199, 0.00118457, 0.00073451, 0.00070052, 0.00144163,\n",
       "       0.00072034])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0, :, :][np.arange(16), captions_out[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_correct_loop_no_mask = np.zeros_like(captions_out, dtype='float')\n",
    "for i in range(25):\n",
    "    for j in range(16):\n",
    "        probs_correct_loop_no_mask[i, j] = probs[i, j, captions_out[i, j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_correct_loop_no_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00108322, 0.00071699, 0.0006498 , 0.00082907, 0.00227525,\n",
       "       0.00113538, 0.00093542, 0.00100416, 0.00150696, 0.00094095,\n",
       "       0.00144199, 0.00118457, 0.00073451, 0.00070052, 0.00144163,\n",
       "       0.00072034])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_correct_loop_no_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(probs_correct_loop_no_mask[0], probs[0, :, :][np.arange(16), captions_out[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compute this using indexing into `probs`. We use solution from [here](https://stackoverflow.com/questions/50785226/extracting-values-from-last-dimension-of-3d-numpy-array). And it seems we get the correct answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 16, 1004), (25, 16))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape, captions_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T, V = probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J = np.ogrid[:N,:T]\n",
    "probs_correct_vect_no_mask = probs[I, J, captions_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(probs_correct_loop_no_mask, probs_correct_vect_no_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's modify our correct score in the loop to account for our mask. Then we can easily compute our loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, dscores = temporal_softmax_loss(scores, captions_out, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.14522802655904"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_correct_loop_with_mask = np.ones_like(captions_out, dtype='float')\n",
    "for i in range(25):\n",
    "    for j in range(16):\n",
    "        if captions_out[i, j]:\n",
    "            probs_correct_loop_with_mask[i, j] = probs[i, j, captions_out[i, j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_loop = -np.sum(np.log(probs_correct_loop_with_mask)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.14522802655904"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In vectorized case we may just multiply by mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_simple = mask[:2, -5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False, False, False],\n",
       "       [ True,  True,  True, False, False]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 0, 0, 0],\n",
       "       [2, 2, 2, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_simple * 2 * np.ones_like(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 16), (25, 16))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape, probs_correct_vect_no_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vect = -np.sum(mask * np.log(probs_correct_vect_no_mask)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.14522802655904"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned in the theory section we just need to remove `1` from correct classes given by `captions_out`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 16, 1004), (25, 16, 1004))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape, dscores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscores_man = probs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscores_man[I, J, captions_out] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscores_man /= N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscores_man *= mask.reshape(N, T, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(dscores, dscores_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our analysis of the softmax loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
